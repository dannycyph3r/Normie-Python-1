{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daniel Adegoke - Lab Evaluation #4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset from Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 27s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (50000, 32, 32, 3)\n",
      "Testing data shape: (10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print('Training data shape:', x_train.shape)\n",
    "print('Testing data shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 1), (10000, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of outputs :  10\n",
      "Output classes :  [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "# Find the unique numbers from the train labels\n",
    "classes = np.unique(y_train)\n",
    "nClasses = len(classes)\n",
    "print('Total number of outputs : ', nClasses)\n",
    "print('Output classes : ', classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {\n",
    " 0: 'airplane',\n",
    " 1: 'automobile',\n",
    " 2: 'bird',\n",
    " 3: 'cat',\n",
    " 4: 'deer',\n",
    " 5: 'dog',\n",
    " 6: 'frog',\n",
    " 7: 'horse',\n",
    " 8: 'ship',\n",
    " 9: 'truck',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_flat = x_train.reshape(-1,3072)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = ['pixel'+str(i) for i in range(x_train_flat.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cifar = pd.DataFrame(x_train_flat,columns=feat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the dataframe: (50000, 3073)\n"
     ]
    }
   ],
   "source": [
    "df_cifar['label'] = y_train\n",
    "print('Size of the dataframe: {}'.format(df_cifar.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel3063</th>\n",
       "      <th>pixel3064</th>\n",
       "      <th>pixel3065</th>\n",
       "      <th>pixel3066</th>\n",
       "      <th>pixel3067</th>\n",
       "      <th>pixel3068</th>\n",
       "      <th>pixel3069</th>\n",
       "      <th>pixel3070</th>\n",
       "      <th>pixel3071</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.231373</td>\n",
       "      <td>0.243137</td>\n",
       "      <td>0.247059</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.188235</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.721569</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.592157</td>\n",
       "      <td>0.462745</td>\n",
       "      <td>0.329412</td>\n",
       "      <td>0.482353</td>\n",
       "      <td>0.360784</td>\n",
       "      <td>0.282353</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.603922</td>\n",
       "      <td>0.694118</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.494118</td>\n",
       "      <td>0.537255</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.407843</td>\n",
       "      <td>0.372549</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.560784</td>\n",
       "      <td>0.521569</td>\n",
       "      <td>0.545098</td>\n",
       "      <td>0.560784</td>\n",
       "      <td>0.525490</td>\n",
       "      <td>0.556863</td>\n",
       "      <td>0.560784</td>\n",
       "      <td>0.521569</td>\n",
       "      <td>0.564706</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.305882</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.325490</td>\n",
       "      <td>0.309804</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.325490</td>\n",
       "      <td>0.313725</td>\n",
       "      <td>0.337255</td>\n",
       "      <td>0.329412</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.109804</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.145098</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.074510</td>\n",
       "      <td>0.149020</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.078431</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.211765</td>\n",
       "      <td>0.184314</td>\n",
       "      <td>0.109804</td>\n",
       "      <td>0.247059</td>\n",
       "      <td>0.219608</td>\n",
       "      <td>0.145098</td>\n",
       "      <td>0.282353</td>\n",
       "      <td>0.254902</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.776471</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>0.698039</td>\n",
       "      <td>0.768627</td>\n",
       "      <td>0.694118</td>\n",
       "      <td>0.725490</td>\n",
       "      <td>0.796078</td>\n",
       "      <td>0.717647</td>\n",
       "      <td>...</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.309804</td>\n",
       "      <td>0.321569</td>\n",
       "      <td>0.278431</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.305882</td>\n",
       "      <td>0.286275</td>\n",
       "      <td>0.301961</td>\n",
       "      <td>0.313725</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 3073 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pixel0    pixel1    pixel2    pixel3    pixel4    pixel5    pixel6  \\\n",
       "0  0.231373  0.243137  0.247059  0.168627  0.180392  0.176471  0.196078   \n",
       "1  0.603922  0.694118  0.733333  0.494118  0.537255  0.533333  0.411765   \n",
       "2  1.000000  1.000000  1.000000  0.992157  0.992157  0.992157  0.992157   \n",
       "3  0.109804  0.098039  0.039216  0.145098  0.133333  0.074510  0.149020   \n",
       "4  0.666667  0.705882  0.776471  0.658824  0.698039  0.768627  0.694118   \n",
       "\n",
       "     pixel7    pixel8    pixel9  ...  pixel3063  pixel3064  pixel3065  \\\n",
       "0  0.188235  0.168627  0.266667  ...   0.847059   0.721569   0.549020   \n",
       "1  0.407843  0.372549  0.400000  ...   0.560784   0.521569   0.545098   \n",
       "2  0.992157  0.992157  0.992157  ...   0.305882   0.333333   0.325490   \n",
       "3  0.137255  0.078431  0.164706  ...   0.211765   0.184314   0.109804   \n",
       "4  0.725490  0.796078  0.717647  ...   0.294118   0.309804   0.321569   \n",
       "\n",
       "   pixel3066  pixel3067  pixel3068  pixel3069  pixel3070  pixel3071  label  \n",
       "0   0.592157   0.462745   0.329412   0.482353   0.360784   0.282353      6  \n",
       "1   0.560784   0.525490   0.556863   0.560784   0.521569   0.564706      9  \n",
       "2   0.309804   0.333333   0.325490   0.313725   0.337255   0.329412      9  \n",
       "3   0.247059   0.219608   0.145098   0.282353   0.254902   0.180392      4  \n",
       "4   0.278431   0.294118   0.305882   0.286275   0.301961   0.313725      1  \n",
       "\n",
       "[5 rows x 3073 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cifar.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca_cifar = PCA(n_components=2)\n",
    "principalComponents_cifar = pca_cifar.fit_transform(df_cifar.iloc[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "principal_cifar_Df = pd.DataFrame(data = principalComponents_cifar\n",
    "             , columns = ['principal component 1', 'principal component 2'])\n",
    "principal_cifar_Df['y'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>principal component 1</th>\n",
       "      <th>principal component 2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6.401018</td>\n",
       "      <td>2.729039</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.829783</td>\n",
       "      <td>-0.949943</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.730200</td>\n",
       "      <td>-11.522102</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-10.347817</td>\n",
       "      <td>0.010738</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.625651</td>\n",
       "      <td>-4.969240</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   principal component 1  principal component 2  y\n",
       "0              -6.401018               2.729039  6\n",
       "1               0.829783              -0.949943  9\n",
       "2               7.730200             -11.522102  9\n",
       "3             -10.347817               0.010738  4\n",
       "4              -2.625651              -4.969240  1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "principal_cifar_Df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variation per principal component: [0.2907663  0.11253144]\n"
     ]
    }
   ],
   "source": [
    "print('Explained variation per principal component: {}'.format(pca_cifar.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test.reshape(-1,32,32,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_flat = x_test.reshape(-1,3072)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=0.9, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit(x_train_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_pca = pca.transform(x_train_flat)\n",
    "test_img_pca = pca.transform(x_test_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-1 \n",
    "## Instruction \n",
    "Fit a Fully connected NN with 4 hidden layer with number of neurons in the 1st hidden layer=1024, 2nd hidden layer=1024, 3rd hidden layer=512, 4th hidden layer=256 on the PCA transformed dataset.\n",
    "\n",
    "Use the optimizer as RMSprop, batch_size= 128, epochs=20, learning_rate=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Parameters\n",
    "n_input = 99 # number of features\n",
    "n_hidden_1 = 1024\n",
    "n_hidden_2 = 1024\n",
    "n_hidden_3 = 512\n",
    "n_hidden_4 = 256\n",
    "num_digits = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Inp = Input(shape=(99,))\n",
    "x1 = Dense(n_hidden_1, activation='relu', name = \"Hidden_Layer_1\")(Inp)\n",
    "x2 = Dense(n_hidden_2, activation='relu', name = \"Hidden_Layer_2\")(x1)\n",
    "x3 = Dense(n_hidden_3, activation='relu', name = \"Hidden_Layer_3\")(x2)\n",
    "x4 = Dense(n_hidden_4, activation='relu', name = \"Hidden_Layer_4\")(x3)\n",
    "output = Dense(num_digits, activation='softmax', name = \"Output_Layer\")(x4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 99)                0         \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_1 (Dense)       (None, 1024)              102400    \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_2 (Dense)       (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_3 (Dense)       (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_4 (Dense)       (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "Output_Layer (Dense)         (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 1,810,698\n",
      "Trainable params: 1,810,698\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(Inp, output)\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "training_epochs = 20\n",
    "batch_size = 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMS = optimizers.RMSprop(learning_rate, rho=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMS,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      " - 10s - loss: 1.6334 - accuracy: 0.4210 - val_loss: 1.4435 - val_accuracy: 0.4843\n",
      "Epoch 2/20\n",
      " - 10s - loss: 1.3242 - accuracy: 0.5306 - val_loss: 1.3532 - val_accuracy: 0.5232\n",
      "Epoch 3/20\n",
      " - 9s - loss: 1.1483 - accuracy: 0.5904 - val_loss: 1.2809 - val_accuracy: 0.5472\n",
      "Epoch 4/20\n",
      " - 10s - loss: 0.9862 - accuracy: 0.6482 - val_loss: 1.3715 - val_accuracy: 0.5411\n",
      "Epoch 5/20\n",
      " - 10s - loss: 0.8379 - accuracy: 0.7008 - val_loss: 1.3434 - val_accuracy: 0.5510\n",
      "Epoch 6/20\n",
      " - 9s - loss: 0.6963 - accuracy: 0.7491 - val_loss: 1.6857 - val_accuracy: 0.5595\n",
      "Epoch 7/20\n",
      " - 10s - loss: 0.5677 - accuracy: 0.7944 - val_loss: 1.5873 - val_accuracy: 0.5625\n",
      "Epoch 8/20\n",
      " - 9s - loss: 0.4677 - accuracy: 0.8346 - val_loss: 1.8941 - val_accuracy: 0.5462\n",
      "Epoch 9/20\n",
      " - 10s - loss: 0.3929 - accuracy: 0.8621 - val_loss: 2.0101 - val_accuracy: 0.5568\n",
      "Epoch 10/20\n",
      " - 10s - loss: 0.3398 - accuracy: 0.8841 - val_loss: 2.0706 - val_accuracy: 0.5558\n",
      "Epoch 11/20\n",
      " - 9s - loss: 0.2973 - accuracy: 0.8983 - val_loss: 2.8008 - val_accuracy: 0.5452\n",
      "Epoch 12/20\n",
      " - 10s - loss: 0.2638 - accuracy: 0.9126 - val_loss: 2.5555 - val_accuracy: 0.5447\n",
      "Epoch 13/20\n",
      " - 9s - loss: 0.2465 - accuracy: 0.9197 - val_loss: 3.1051 - val_accuracy: 0.5560\n",
      "Epoch 14/20\n",
      " - 10s - loss: 0.2308 - accuracy: 0.9255 - val_loss: 3.0791 - val_accuracy: 0.5567\n",
      "Epoch 15/20\n",
      " - 9s - loss: 0.2214 - accuracy: 0.9302 - val_loss: 3.0543 - val_accuracy: 0.5458\n",
      "Epoch 16/20\n",
      " - 9s - loss: 0.2058 - accuracy: 0.9356 - val_loss: 3.3598 - val_accuracy: 0.5443\n",
      "Epoch 17/20\n",
      " - 9s - loss: 0.1956 - accuracy: 0.9382 - val_loss: 3.3276 - val_accuracy: 0.5490\n",
      "Epoch 18/20\n",
      " - 9s - loss: 0.1887 - accuracy: 0.9425 - val_loss: 3.5370 - val_accuracy: 0.5512\n",
      "Epoch 19/20\n",
      " - 10s - loss: 0.1921 - accuracy: 0.9434 - val_loss: 3.4785 - val_accuracy: 0.5491\n",
      "Epoch 20/20\n",
      " - 9s - loss: 0.1767 - accuracy: 0.9469 - val_loss: 3.3537 - val_accuracy: 0.5443\n"
     ]
    }
   ],
   "source": [
    "history1 = model.fit(train_img_pca, y_train,\n",
    "                     batch_size = batch_size,\n",
    "                     epochs = training_epochs,\n",
    "                     verbose = 2,\n",
    "                     validation_data=(test_img_pca, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-2\n",
    "## Instruction \n",
    "Fit a Fully connected NN with 4 hidden layer with number of neurons in the 1st hidden layer=1024, 2nd hidden layer=1024, 3rd hidden layer=512, 4th hidden layer=256 on the original dataset.\n",
    "\n",
    "Use the optimizer as RMSprop, batch_size= 128, epochs=20, learning_rate=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Parameters\n",
    "n_input = 99 # number of features\n",
    "n_hidden_1 = 1024\n",
    "n_hidden_2 = 1024\n",
    "n_hidden_3 = 512\n",
    "n_hidden_4 = 256\n",
    "num_digits = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3072)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "Inp = Input(shape=(3072,))\n",
    "x1 = Dense(n_hidden_1, activation='relu', name = \"Hidden_Layer_1\")(Inp)\n",
    "x2 = Dense(n_hidden_2, activation='relu', name = \"Hidden_Layer_2\")(x1)\n",
    "x3 = Dense(n_hidden_3, activation='relu', name = \"Hidden_Layer_3\")(x2)\n",
    "x4 = Dense(n_hidden_4, activation='relu', name = \"Hidden_Layer_4\")(x3)\n",
    "output = Dense(num_digits, activation='softmax', name = \"Output_Layer\")(x4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_1 (Dense)       (None, 1024)              3146752   \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_2 (Dense)       (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_3 (Dense)       (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_4 (Dense)       (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "Output_Layer (Dense)         (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 4,855,050\n",
      "Trainable params: 4,855,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(Inp, output)\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "training_epochs = 20\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMS = optimizers.RMSprop(learning_rate, rho=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMS,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      " - 22s - loss: 2.1844 - accuracy: 0.2372 - val_loss: 1.8840 - val_accuracy: 0.3113\n",
      "Epoch 2/20\n",
      " - 22s - loss: 1.8377 - accuracy: 0.3388 - val_loss: 1.7727 - val_accuracy: 0.3531\n",
      "Epoch 3/20\n",
      " - 22s - loss: 1.7369 - accuracy: 0.3763 - val_loss: 1.9131 - val_accuracy: 0.3316\n",
      "Epoch 4/20\n",
      " - 22s - loss: 1.6686 - accuracy: 0.4029 - val_loss: 1.8241 - val_accuracy: 0.3728\n",
      "Epoch 5/20\n",
      " - 23s - loss: 1.6120 - accuracy: 0.4218 - val_loss: 1.7142 - val_accuracy: 0.3938\n",
      "Epoch 6/20\n",
      " - 22s - loss: 1.5721 - accuracy: 0.4384 - val_loss: 1.5603 - val_accuracy: 0.4523\n",
      "Epoch 7/20\n",
      " - 23s - loss: 1.5273 - accuracy: 0.4535 - val_loss: 1.5892 - val_accuracy: 0.4321\n",
      "Epoch 8/20\n",
      " - 23s - loss: 1.5041 - accuracy: 0.4639 - val_loss: 1.5198 - val_accuracy: 0.4648\n",
      "Epoch 9/20\n",
      " - 22s - loss: 1.4765 - accuracy: 0.4743 - val_loss: 1.6349 - val_accuracy: 0.4210\n",
      "Epoch 10/20\n",
      " - 23s - loss: 1.4447 - accuracy: 0.4848 - val_loss: 1.9170 - val_accuracy: 0.3744\n",
      "Epoch 11/20\n",
      " - 22s - loss: 1.4273 - accuracy: 0.4929 - val_loss: 1.5162 - val_accuracy: 0.4727\n",
      "Epoch 12/20\n",
      " - 23s - loss: 1.4119 - accuracy: 0.4961 - val_loss: 1.4981 - val_accuracy: 0.4924\n",
      "Epoch 13/20\n",
      " - 22s - loss: 1.3908 - accuracy: 0.5071 - val_loss: 1.5384 - val_accuracy: 0.4718\n",
      "Epoch 14/20\n",
      " - 23s - loss: 1.3729 - accuracy: 0.5105 - val_loss: 1.5596 - val_accuracy: 0.4685\n",
      "Epoch 15/20\n",
      " - 23s - loss: 1.3528 - accuracy: 0.5191 - val_loss: 1.6495 - val_accuracy: 0.4606\n",
      "Epoch 16/20\n",
      " - 22s - loss: 1.3409 - accuracy: 0.5225 - val_loss: 1.5502 - val_accuracy: 0.4913\n",
      "Epoch 17/20\n",
      " - 23s - loss: 1.3203 - accuracy: 0.5306 - val_loss: 1.5129 - val_accuracy: 0.4806\n",
      "Epoch 18/20\n",
      " - 23s - loss: 1.3019 - accuracy: 0.5364 - val_loss: 1.5355 - val_accuracy: 0.4906\n",
      "Epoch 19/20\n",
      " - 23s - loss: 1.2954 - accuracy: 0.5419 - val_loss: 1.7638 - val_accuracy: 0.4640\n",
      "Epoch 20/20\n",
      " - 22s - loss: 1.2795 - accuracy: 0.5481 - val_loss: 1.6722 - val_accuracy: 0.4936\n"
     ]
    }
   ],
   "source": [
    "history1 = model.fit(x_train_flat, y_train,\n",
    "                     batch_size = batch_size,\n",
    "                     epochs = training_epochs,\n",
    "                     verbose = 2,\n",
    "                     validation_data=(x_test_flat, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-3\n",
    "## Write a conclusion on the above two models\n",
    "For example is any of the model overfitting, if so why? Which model is better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model is overfitted with an accuracy of 94% , the the 2nd model has an accuracy of 54.8%, therefore PCA dataset is overfitted by the model. It performs very well on preparing dataset however inadequately on the vadildation dataset. \n",
    "\n",
    "However, Using the orginal dataset, the model performs well on the training dataset and the validation dataset also. In totality, this model is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
